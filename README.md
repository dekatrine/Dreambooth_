# Dreambooth

Dreambooth

1.	Что это такое?

Stable diffusion представляет собой параметризованную цепь Маркова, обученную с использованием вариационного вывода для создания выборок, соответствующих данным, за конечное число шагов. Процесс диффузии — это цепь Маркова, которая постепенно добавляет шум к данным в направлении, противоположном семплированию, пока сигнал не будет разрушен. Происходит обучение обратных переходов в этой цепочке, которые обращают вспять процесс диффузии и всё это параметризуется нейронными сетями. Они гибки, чтобы выучить любое произвольно сложное распределение данных, и в то же время поддаются аналитической оценке выученного распределения. Недавно было показано, что диффузионные модели могут генерировать высококачественные изображения и по своим характеристикам не уступают SOTA GAN.

Новый подход к персонализации text-to-image diffusion models – DreamBooth model.

DreamBooth представляет новый подход к "персонализации" моделей "txt2img",  делая упор на их потребностях пользователей. Предварительно обученная модель настраивается путем добавления всего нескольких изображений объекта и соответствующего имени класса в качестве входных данных. Модель связывает уникальный идентификатор с этим конкретным объектом. 

DreamBooth способен файнтюнить предобученные модели (Imagen) небольшим числом картинок (3-5) конкретного персонажа, так что модель выучивала уникальный идентификатор (например, “[V]”) субъекта, и его можно далее было использовать для синтеза картинок с этим субъектом в различных новых контекстах (“A [V] dog in the beach”). 

Особенности DreamBooth:
•	Модель может улучшать модель преобразования текста в изображение с 3-5 изображениями.
•	Модель может создавать фотореалистичные изображения
•	Модель может создавать изображения с разных ракурсов и позиций
В чем основная идея DreamBooth:

## *Общая концепция*: увеличить словарный запас лингвистического зрения и связать необычные идентификаторы токенов с настраиваемыми темами, которые могут быть определены пользователем. Основная задача этой модели - подключить пользователя к модели диффузии текста в изображение, предоставив ресурсы, необходимые для создания графического представления выбранного пользователем той или иной темы.
2.	Почему над этим работают?

Цель данного проекта - предоставить пользователям эффективный инструмент для синтеза личных объектов (животных, предметов) в различных контекстах. В то время как общие модели преобразования текста в изображение могут быть смещены в сторону определенных атрибутов при синтезе изображений из текста, наш подход позволяет пользователю получить более точную реконструкцию желаемых объектов. Напротив, злоумышленники могут попытаться использовать такие изображения для введения зрителей в заблуждение. Это общая проблема, существующая в других подходах генеративных моделей или методах манипулирования контентом. Будущие исследования в области генеративного моделирования и, в частности, персонализированных генеративных приор, должны продолжить изучение и переоценку этих проблем.

Эта нейронная сеть подходит для веб-дизайнеров, создающих уникальный графический контент, художников, придумывающих новые идеи для иллюстраций, а также разработчиков и менеджеров по работе с партнерами. Кроме того, ее можно использовать в сочетании с DALL-E 2 и Stable Diffusion. Однако системные требования к ней жестко заданы, поэтому начинающим пользователям следует заранее проверить характеристики своего ПК.

3.	Как формулируется задача?
   
Задача: моделям не хватает способности имитировать внешний вид объектов в заданном эталонном наборе и синтезировать их новые изображения в различных контекстах. 

Решение: новый подход к "персонализации" моделей преобразования текста в изображение. Получив на вход несколько изображений объекта, мы настраиваем предварительно обученную модель "текст-изображение" таким образом, чтобы она научилась связывать уникальный идентификатор с этим объектом. После того как объект встраивается в выходную область модели, уникальный идентификатор может быть использован для синтеза новых фотореалистичных изображений объекта в контексте различных сцен. Используя семантическое предшествование, встроенное в модель, и новую потерю сохранения предшествования, специфичную для автогенного класса, наша методика позволяет синтезировать объект в различных сценах, позах, ракурсах и условиях освещения, которые не встречаются на эталонных изображениях. 

Дальнейшее применение: решения нескольких ранее недоступных задач, включая реконтекстуализацию объекта, синтез ракурса с помощью текста и художественную визуализацию, сохраняя при этом ключевые особенности объекта. Мы также предоставляем новый набор данных и протокол оценки для этой новой задачи генерации, управляемой объектом. 

# Аннотация
В научной статье рассматривается новый персонализированный подход модели text-to-image, который решает проблему остальных: невозможность представить объекты в определенных условиях. DreamBooth может распознавать тему изображения, деконструировать ее из исходного контекста, а затем точно синтезировать в новый желаемый контекстю Цель состоит в том, чтобы внедрить объект в исходную область модели таким образом, чтобы его можно было синтезировать с помощью уникального идентификатора. Таким образом, появляется новая технология для представления данного субъекта с редкими идентификаторами токенов и тонкой настройки предварительно обученной структуры преобразования текста в изображение на основе диффузии. Модель решает эту новую сложную проблему генерации, основанной на объекте, позволяя пользователям, из нескольких случайных изображений объекта, синтезировать новые представления предмета в разных контекстах, сохраняя при этом его отличительные черты. В данной моделе зайдествованы такие методы как: методы композиции изображений (направлены на клонирование заданного объекта в новый фон, 3D-реконструкции для создания новых позиций), редактирование и синтезирование текста к изображению (использованием GANs в сочетании с image-text), контролируемые генеративные модели(технику, основанную на диффузии, позволяющую вариации изображения, предоставление пользователем маски для ограничения измененной области, инверсия, метод Prompt-to-prompt позволяет осуществлять локальное и глобальное редактирование без маски ввода). DreamBooth нацелен на генерацию новых изображений объекта с высокой точностью детализации и с вариациями, управляемыми текстовыми подсказками. Примеры: изменение местоположения объекта, изменение свойств объекта, , позы субъекта, и другие семантические изменения. Модель состоит настройки модель с использованием набора данных объекта с несколькими снимками, учитывая тщательную тонкую настройку. 
Наша цель - "имплантировать" новую (уникальный идентификатор, предмет) пару в "словарь" диффузионной модели. Чтобы пройти накладные расходы на написание подробных описаний изображений для данного набора изображений, мы выберем более простой подход и помечаем все входные изображения субъекта «[идентификатор] [класс]», где [идентификатор] является уникальным идентификатором, связанным с объектом, а [класс] является грубым дескриптором класса объекта (например, кошка, собака, часы и т. д.). Дескриптор класса может быть предоставлен пользователем или получен с помощью классификатора.
В ходе экспериментов метод позволяет использовать большое количество текстовых семантических модификаций наших предметных экземпляров, включая реконтекстуализацию, модификацию субъектных свойств, таких как материал и вид, художественную реализацию и модификацию точки зрения, при этом сохраняя уникальные визуальные особенности, которые придают предмету его идентичность. Если задача является реконтекстуальной, то особенности субъекта не изменены, но восприятие (например, поза) может измениться. Если задача является более сильной семантической модификацией, такой как пересечение между нашим подобъектом и другим видом/объектом, то ключевые особенности субъекта сохраняются после модификации. В этом разделе мы ссылаемся на уникальный идентификатор субъекта, используя [V]. Эксперименты показали себя довольно хорошо.

